--- avifile-0.7-0.7.45/lib/aviread/FFReadHandler.cpp.orig	2013-07-16 16:48:12.312338353 +0200
+++ avifile-0.7-0.7.45/lib/aviread/FFReadHandler.cpp	2013-07-19 17:06:37.738081034 +0200
@@ -46,14 +46,12 @@
 
 int FFReadHandler::Init(const char* url)
 {
-    AVFormatParameters avfp;
     AVInputFormat* fmt = 0;
     // av_find_input_format(url);
     // printf("find input format  %p   %s\n", fmt, url);
-    memset(&avfp, 0, sizeof(avfp));
     //if (!fmt)  return -1;
-    int r = av_open_input_file(&m_pContext, url,
-			       fmt, 64000, &avfp);
+    int r = avformat_open_input(&m_pContext, url,
+			       fmt, NULL);
     if (r < 0)
     {
 	AVM_WRITE("FF reader", "OPEN INPUT failed\n");
@@ -100,8 +98,8 @@
     uint_t j = 0;
     switch (type)
     {
-    case IStream::Audio: t = CODEC_TYPE_AUDIO; break;
-    case IStream::Video: t = CODEC_TYPE_VIDEO; break;
+    case IStream::Audio: t = AVMEDIA_TYPE_AUDIO; break;
+    case IStream::Video: t = AVMEDIA_TYPE_VIDEO; break;
     default: return 0;
     }
 
@@ -125,8 +123,8 @@
 
     switch (type)
     {
-    case IStream::Audio: t = CODEC_TYPE_AUDIO; break;
-    case IStream::Video: t = CODEC_TYPE_VIDEO; break;
+    case IStream::Audio: t = AVMEDIA_TYPE_AUDIO; break;
+    case IStream::Video: t = AVMEDIA_TYPE_VIDEO; break;
     default: return 0;
     }
 
@@ -152,7 +150,7 @@
 int FFReadHandler::seek(framepos_t pos)
 {
     Locker locker(m_Mutex);
-    url_fseek(m_pContext->pb, 0, SEEK_SET);
+    avio_seek(m_pContext->pb, 0, SEEK_SET);
     flush();
     //av_find_stream_info(m_pContext);
     return 0;
@@ -177,8 +175,8 @@
 	AVFrame pic;
 	int got_pic = 0;
 	memset(&pic, 0, sizeof(pic));
-	int r = avcodec_decode_video(s->m_pAvContext,
-				     &pic, &got_pic, pkt.data, pkt.size);
+	int r = avcodec_decode_video2(s->m_pAvContext,
+				     &pic, &got_pic, &pkt);
 	AVM_WRITE("FF reader", "____  %d   %d\n", r, got_pic);
     }
     //printf("FFMPEG pktsize: %u %llu   %d\n", pkt.size, pkt.pts, pkt.stream_index);fflush(stdout);
@@ -203,19 +201,19 @@
 	    / st->codec.frame_rate;
     }
 #endif
-    //if (st->codec.codec_type == CODEC_TYPE_VIDEO) printf("FRATE %d pts:%lld %d  %d  t:%lld\n", p->position, pkt.pts,st->codec.frame_rate_base, st->codec.frame_rate, p->timestamp);
+    //if (st->codec.codec_type == AVMEDIA_TYPE_VIDEO) printf("FRATE %d pts:%lld %d  %d  t:%lld\n", p->position, pkt.pts,st->codec.frame_rate_base, st->codec.frame_rate, p->timestamp);
     //else printf("Bitrate  %d\n", st->codec.bit_rate);
     //printf("TIMESTAMP %lld    %d %d   bitrate:%d\n", p->timestamp, s->m_pAvStream->r_frame_rate_base, s->m_pAvStream->r_frame_rate, st->codec.bit_rate);
 
     switch (st->codec->codec_type)
     {
-    case CODEC_TYPE_AUDIO:
+    case AVMEDIA_TYPE_AUDIO:
 	if (!pkt.pts && st->codec->bit_rate)
 	    p->timestamp = (int64_t)p->position * 8 * 1000000 /
 		st->codec->bit_rate;
 	s->m_uiPosition += pkt.size;
 	break;
-    case CODEC_TYPE_VIDEO:
+    case AVMEDIA_TYPE_VIDEO:
     default:
 	s->m_uiPosition++;
 	break;
@@ -227,7 +225,7 @@
 	   pkt.stream_index, m_Streams[pkt.stream_index]->m_Packets.size(),
 	   pkt.pts, pkt.size, p->timestamp, pkt.flags);
 #endif
-    if (pkt.flags & PKT_FLAG_KEY)
+    if (pkt.flags & AV_PKT_FLAG_KEY)
 	p->flags |= KEYFRAME;
     av_free_packet(&pkt);
 
--- avifile-0.7-0.7.45/lib/aviread/FFReadStream.cpp.orig	2013-07-19 17:08:37.194742686 +0200
+++ avifile-0.7-0.7.45/lib/aviread/FFReadStream.cpp	2013-07-19 17:45:26.764649961 +0200
@@ -18,7 +18,7 @@
 AVM_BEGIN_NAMESPACE;
 
 static const struct id2fcc {
-    enum CodecID id;
+    enum AVCodecID id;
     uint32_t fcc;
 } id2fcct[] = {
     { CODEC_ID_MPEG1VIDEO, RIFFINFO_MPG1 },
@@ -32,7 +32,7 @@
     { CODEC_ID_NONE }
 };
 
-static int get_fcc(enum CodecID id)
+static int get_fcc(enum AVCodecID id)
 {
     for (const struct id2fcc* p = id2fcct; p->id; p++)
 	if (p->id == id)
@@ -53,15 +53,15 @@
     //printf("CODECRA %d  %d   %d\n", avs->codec.frame_rate, avs->codec->frame_rate_base, m_pAvStream->r_frame_rate_base);
     if (0 && avs->codec->codec_id == CODEC_ID_MPEG1VIDEO)
     {
-	m_pAvContext = avcodec_alloc_context();
+	m_pAvContext = avcodec_alloc_context3(NULL);
 	//AVCodec* codec = avcodec_find_encoder(avs->codec->codec_id);
 	if (m_pAvContext)
 	{
 	    AVCodec* codec = avcodec_find_decoder(avs->codec->codec_id);
-	    if (codec && avcodec_open(m_pAvContext, codec) == 0)
+	    if (codec && avcodec_open2(m_pAvContext, codec, NULL) == 0)
 	    {
 		m_pAvContext->flags |= CODEC_FLAG_TRUNCATED;
-		m_pAvContext->hurry_up = 5;
+		m_pAvContext->skip_idct = m_pAvContext->skip_frame = AVDISCARD_ALL;
 		//printf("Opened hurryup decoder %p  %p\n", codec, m_pAvContext->codec->decode);
 	    }
 	    else
@@ -148,7 +148,7 @@
 
 	switch (avs->codec->codec_type)
 	{
-	case CODEC_TYPE_AUDIO:
+	case AVMEDIA_TYPE_AUDIO:
 	    m_StreamInfo.m_p->setAudio(avs->codec->channels,
 				       avs->codec->sample_rate,
 				       avs->codec->frame_bits);
@@ -157,7 +157,7 @@
 	    AVM_WRITE("FF stream", "Audio Format:  %.4s (0x%x)\n",
 		      (const char*)&avs->codec->codec_tag, avs->codec->codec_tag);
 	    break;
-	case CODEC_TYPE_VIDEO:
+	case AVMEDIA_TYPE_VIDEO:
 	    m_StreamInfo.m_p->setVideo(avs->codec->width, avs->codec->height,
 				       0, avs->codec->sample_aspect_ratio.num /
 				       (float) avs->codec->sample_aspect_ratio.den);
@@ -191,8 +191,8 @@
 {
     switch (m_pHandler->m_pContext->streams[m_uiSId]->codec->codec_type)
     {
-    case CODEC_TYPE_AUDIO: return IStream::Audio;
-    case CODEC_TYPE_VIDEO: return IStream::Video;
+    case AVMEDIA_TYPE_AUDIO: return IStream::Audio;
+    case AVMEDIA_TYPE_VIDEO: return IStream::Video;
     default: return IStream::Other;
     }
 }
@@ -202,7 +202,7 @@
     AVStream* avs = m_pHandler->m_pContext->streams[m_uiSId];
     switch (avs->codec->codec_type)
     {
-    case CODEC_TYPE_AUDIO:
+    case AVMEDIA_TYPE_AUDIO:
 	if (pFormat && lSize >= sizeof(WAVEFORMATEX))
 	{
 	    WAVEFORMATEX* wf = (WAVEFORMATEX*) pFormat;
@@ -228,7 +228,7 @@
 	//printf("EEEEEEEEEEE %d\n", avs->codec->extradata_size);
 	return sizeof(WAVEFORMATEX)
 	    + ((avs->codec->extradata) ? avs->codec->extradata_size : 0);
-    case CODEC_TYPE_VIDEO:
+    case AVMEDIA_TYPE_VIDEO:
 	if (pFormat && lSize >= sizeof(BITMAPINFOHEADER))
 	{
 	    BITMAPINFOHEADER* bh = (BITMAPINFOHEADER*) pFormat;
@@ -312,7 +312,7 @@
 {
     if (time < 1.)
     {
-	if (m_pAvStream->codec->codec_type == CODEC_TYPE_AUDIO)
+	if (m_pAvStream->codec->codec_type == AVMEDIA_TYPE_AUDIO)
             // check if more streams are available
             // and seek only with the video
             return 0;
--- avifile-0.7-0.7.45/lib/codeckeeper.cpp.orig	2013-07-19 17:48:46.567974909 +0200
+++ avifile-0.7-0.7.45/lib/codeckeeper.cpp	2013-07-19 17:53:49.324628870 +0200
@@ -295,7 +295,6 @@
     audio_codecs.clear();
 
     // FFMPEG initialization
-    avcodec_init();
     avcodec_register_all();
 
     uncompressed_FillPlugins(video_codecs);
--- avifile-0.7-0.7.45/plugins/libffmpeg/libffmpeg.cpp.orig	2006-03-05 21:44:59.000000000 +0100
+++ avifile-0.7-0.7.45/plugins/libffmpeg/libffmpeg.cpp	2013-07-19 18:00:25.221278922 +0200
@@ -137,7 +137,6 @@
     static int is_init = 0;
     if (!is_init)
     {
-	avcodec_init();
 	avcodec_register_all();
 	is_init++;
     }
--- avifile-0.7-0.7.45/plugins/libffmpeg/FFAudioDecoder.cpp.orig	2013-07-19 18:01:05.454610568 +0200
+++ avifile-0.7-0.7.45/plugins/libffmpeg/FFAudioDecoder.cpp	2013-07-19 18:15:09.351241818 +0200
@@ -25,7 +25,7 @@
 {
     if (!m_pAvContext)
     {
-	m_pAvContext = avcodec_alloc_context();
+	m_pAvContext = avcodec_alloc_context3(NULL);
 	m_pAvContext->channels = m_pFormat->nChannels;
 	if (m_pAvContext->channels > 2)
 	    m_pAvContext->channels = 2;
@@ -33,7 +33,7 @@
 	m_pAvContext->sample_rate = m_pFormat->nSamplesPerSec;
 	m_pAvContext->block_align = m_pFormat->nBlockAlign;
 	m_pAvContext->codec_tag = m_Info.fourcc;
-	m_pAvContext->codec_id = (CodecID) m_pAvCodec->id;
+	m_pAvContext->codec_id = (AVCodecID) m_pAvCodec->id;
 
 	if (m_pFormat->cbSize > 0)
 	{
@@ -41,7 +41,7 @@
 	    m_pAvContext->extradata_size = m_pFormat->cbSize;
 	}
 
-	if (avcodec_open(m_pAvContext, m_pAvCodec) < 0)
+	if (avcodec_open2(m_pAvContext, m_pAvCodec, NULL) < 0)
 	{
 	    AVM_WRITE("FFAudioDecoder", "WARNING: can't open avcodec\n");
 	    free(m_pAvContext);
@@ -50,8 +50,12 @@
 	}
     }
     int framesz = 0;
-    int hr = avcodec_decode_audio2(m_pAvContext, (int16_t*)out_data, &framesz,
-				  (uint8_t*)in_data, in_size);
+    AVPacket avpkt;
+    av_init_packet(&avpkt);
+    avpkt.data = (uint8_t*)in_data;
+    avpkt.size = in_size;
+    int hr = avcodec_decode_audio3(m_pAvContext, (int16_t*)out_data, &framesz,
+				  &avpkt);
     //printf("CONVERT  i:%d  o:%d  f:%d   h:%d\n", in_size, out_size, framesz, hr);
     if (size_read)
 	*size_read = (hr < 0) ? in_size : hr;
--- avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoDecoder.cpp.orig	2013-07-19 18:15:45.704573627 +0200
+++ avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoDecoder.cpp	2013-07-19 20:13:57.874275997 +0200
@@ -101,36 +101,29 @@
     pic->pts = pImage->m_lTimestamp;
     pic->type = FF_BUFFER_TYPE_USER;
     pImage->m_iType = pic->pict_type;
-    //pic->age = pic->coded_picture_number - pImage->m_iAge;
-    //pImage->m_iAge = (pic->pict_type == FF_B_TYPE) ?
+    //pImage->m_iAge = (pic->pict_type == AV_PICTURE_TYPE_B) ?
     //pImage->m_iAge = (pic->reference) ?
     //    -256*256*256*64 : pic->coded_picture_number;
 
     d->m_iAgeIP[0]++;
-    pic->age = d->m_iAgeIP[0] - pImage->m_iAge;
-    pImage->m_iAge = (pic->pict_type == FF_B_TYPE) ?
+    pImage->m_iAge = (pic->pict_type == AV_PICTURE_TYPE_B) ?
 	256*256*256*64 : d->m_iAgeIP[0];
-    if (pic->age < 1)
-	pic->age = 256*256*256*64;
 
 #if 0
     // mplayer code
     if (pic->reference)
     {
-        pic->age = d->m_iAgeIP[0];
 	d->m_iAgeIP[0] = d->m_iAgeIP[1] + 1;
         d->m_iAgeIP[1] = 1;
         d->m_iAgeB++;
     }
     else
     {
-	pic->age = d->m_iAgeB;
         d->m_iAgeIP[0]++;
         d->m_iAgeIP[1]++;
         d->m_iAgeB = 1;
     }
 #endif
-    //printf("Age %d  %d   cp:%d   %p\n", pic->age, pImage->m_iAge, pic->coded_picture_number, pImage);
     //printf("PictType %d   %d\n", pic->pict_type, pic->reference);
     //printf("%p %p %p  %d  %d\n", avctx->dr_buffer[0], avctx->dr_buffer[1], avctx->dr_buffer[2], avctx->dr_stride, avctx->dr_uvstride);
     return 0;
@@ -172,7 +165,7 @@
     //printf("FFMPEG space  \n"); m_Dest.Print(); pImage->GetFmt()->Print();
     if (!m_pAvContext)
     {
-	m_pAvContext = avcodec_alloc_context();
+	m_pAvContext = avcodec_alloc_context3(NULL);
         // for autodetection errors
 	m_pAvContext->codec_tag = m_pFormat->biCompression;
 	m_pAvContext->bits_per_coded_sample = m_pFormat->biBitCount;
@@ -198,8 +191,6 @@
 	{
             m_pAvContext->extradata_size = m_pFormat->biSize - sizeof(BITMAPINFOHEADER);
 	    m_pAvContext->extradata = (uint8_t*) m_pFormat + sizeof(BITMAPINFOHEADER);
-	    if (m_pAvContext->extradata_size > 40)
-		m_pAvContext->flags |= CODEC_FLAG_EXTERN_HUFF; // somewhat useless
 	}
 
 	m_uiBuffers = (pImage && pImage->GetAllocator()) ? pImage->GetAllocator()->GetImages() : 0;
@@ -297,7 +288,7 @@
 		m_pAvContext->workaround_bugs |= p->flag;
 	}
 */
-	if (avcodec_open(m_pAvContext, m_pAvCodec) < 0)
+	if (avcodec_open2(m_pAvContext, m_pAvCodec, NULL) < 0)
 	{
 	    AVM_WRITE(m_Info.GetPrivateName(), "WARNING: FFVideoDecoder::DecodeFrame() can't open avcodec\n");
             Stop();
@@ -317,9 +308,13 @@
     m_bUsed = false;
     m_pReleased = 0;
     AVFrame pic;
+    AVPacket avpkt;
     int got_picture = 0;
-    int hr = avcodec_decode_video(m_pAvContext, &pic, &got_picture,
-				  (unsigned char*) src, size);
+    av_init_packet(&avpkt);
+    avpkt.data = (unsigned char*)src;
+    avpkt.size = size;
+    int hr = avcodec_decode_video2(m_pAvContext, &pic, &got_picture,
+				  &avpkt);
     //printf("DECFF got_picture  %d  %p   del:%d  hr:%d size:%d\n", got_picture, src, m_pAvContext->delay, hr, size);
     //printf("PictType  %d\n", m_pAvContext->pict_type);
     //static int ctr=0; printf("WIDTH %dx%d  %d  r:%d\n", m_pAvContext->width, m_pAvContext->height, ctr++, m_pAvContext->pict_type);
@@ -365,7 +360,7 @@
     }
 
     Debug printf("FF: r=0x%x  sz=%d  %d  b:%d  img:%p  out:%p\n", hr, size, got_picture, m_bUsed, pImage, pOut);
-    Debug printf("FF: frame_size %d  number %d  picnum %d\n", m_pAvContext->frame_size, m_pAvContext->frame_number, m_pAvContext->real_pict_num);
+    Debug printf("FF: frame_size %d  number %d\n", m_pAvContext->frame_size, m_pAvContext->frame_number);
     if (!got_picture)
     {
 	Debug printf("FF: NO PICTURE  released=%p\n", m_pReleased);
@@ -388,8 +383,8 @@
 	switch (m_pAvContext->pix_fmt)
 	{
 	case PIX_FMT_BGR24: imfmt = IMG_FMT_BGR24; break;
-	case PIX_FMT_RGBA32: imfmt = IMG_FMT_BGR32; break;
-	case PIX_FMT_YUV422: imfmt = IMG_FMT_YUY2; break;
+	case PIX_FMT_RGB32: imfmt = IMG_FMT_BGR32; break;
+	case PIX_FMT_YUYV422: imfmt = IMG_FMT_YUY2; break;
 	case PIX_FMT_YUV410P: imfmt = IMG_FMT_I410; break;
 	case PIX_FMT_YUV411P: imfmt = IMG_FMT_I411; break;
 	case PIX_FMT_YUV420P: imfmt = IMG_FMT_I420; break;
--- avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoEncoder.cpp.orig	2005-09-12 14:06:48.000000000 +0200
+++ avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoEncoder.cpp	2013-07-19 20:15:08.434273035 +0200
@@ -122,7 +122,7 @@
 
     if (!m_pAvContext)
     {
-	m_pAvContext = avcodec_alloc_context();
+	m_pAvContext = avcodec_alloc_context3(NULL);
         m_pAvContext->width = m_bh.biWidth;
 	m_pAvContext->height = m_obh.biHeight;
 	//m_pAvContext->pix_fmt = PIX_FMT_YUV420P;
@@ -138,7 +138,7 @@
 
         printf("CODEC opening  %dx%d\n", m_bh.biWidth, m_obh.biHeight);
 
-	if (avcodec_open(m_pAvContext, m_pAvCodec) < 0)
+	if (avcodec_open2(m_pAvContext, m_pAvCodec, NULL) < 0)
 	{
 	    free(m_pAvContext);
 	    m_pAvContext = 0;
--- avifile-0.7-0.7.45/lib/aviread/FFReadHandler.cpp.orig	2020-08-29 20:43:18.688873368 +0200
+++ avifile-0.7-0.7.45/lib/aviread/FFReadHandler.cpp	2020-08-29 20:43:43.955403155 +0200
@@ -40,7 +40,7 @@
 	    delete m_Streams.back();
             m_Streams.pop_back();
 	}
-        av_close_input_file(m_pContext);
+        avformat_close_input(&m_pContext);
     }
 }
 
@@ -58,7 +58,7 @@
 	return -1;
     }
 
-    if (av_find_stream_info(m_pContext) < 0)
+    if (avformat_find_stream_info(m_pContext, NULL) < 0)
 	return -1;
 
     AVM_WRITE("FF reader", "Format  %s   streams:%d\n", m_pContext->iformat->long_name, m_pContext->nb_streams);
@@ -161,9 +161,9 @@
     Locker locker(m_Mutex);
     AVPacket pkt;
     AVM_WRITE("FF reader", "readPacket()\n");
-    if (av_read_packet(m_pContext, &pkt) < 0)
+    if (av_read_frame(m_pContext, &pkt) < 0)
     {
-        if (!url_feof(m_pContext->pb))
+        if (!avio_feof(m_pContext->pb))
 	    AVM_WRITE("FF reader", "ffmpeg packet error and not eof??\n");
         return -1;
     }
--- avifile-0.7-0.7.45/lib/aviread/FFReadStream.cpp.orig	2020-08-29 20:22:05.882435419 +0200
+++ avifile-0.7-0.7.45/lib/aviread/FFReadStream.cpp	2020-08-29 20:46:33.481151421 +0200
@@ -21,15 +21,15 @@
     enum AVCodecID id;
     uint32_t fcc;
 } id2fcct[] = {
-    { CODEC_ID_MPEG1VIDEO, RIFFINFO_MPG1 },
-    { CODEC_ID_H263, mmioFOURCC('H', '2', '6', '3') },
-    { CODEC_ID_H263P, mmioFOURCC('H', '2', '6', '3') },
-    { CODEC_ID_MP2, 0x50 },
-    { CODEC_ID_MP3, 0x55 },
-    { CODEC_ID_AC3, 0x2000 },
-    { CODEC_ID_DVVIDEO, mmioFOURCC('D', 'V', 'S', 'D') },
-    { CODEC_ID_DVAUDIO, ('D' << 8) | 'A' },
-    { CODEC_ID_NONE }
+    { AV_CODEC_ID_MPEG1VIDEO, RIFFINFO_MPG1 },
+    { AV_CODEC_ID_H263, mmioFOURCC('H', '2', '6', '3') },
+    { AV_CODEC_ID_H263P, mmioFOURCC('H', '2', '6', '3') },
+    { AV_CODEC_ID_MP2, 0x50 },
+    { AV_CODEC_ID_MP3, 0x55 },
+    { AV_CODEC_ID_AC3, 0x2000 },
+    { AV_CODEC_ID_DVVIDEO, mmioFOURCC('D', 'V', 'S', 'D') },
+    { AV_CODEC_ID_DVAUDIO, ('D' << 8) | 'A' },
+    { AV_CODEC_ID_NONE }
 };
 
 static int get_fcc(enum AVCodecID id)
@@ -51,7 +51,7 @@
 	      m_pHandler->m_pContext->start_time, m_pHandler->m_pContext->duration);
     m_dLength = m_pHandler->m_pContext->duration / (double) AV_TIME_BASE;
     //printf("CODECRA %d  %d   %d\n", avs->codec.frame_rate, avs->codec->frame_rate_base, m_pAvStream->r_frame_rate_base);
-    if (0 && avs->codec->codec_id == CODEC_ID_MPEG1VIDEO)
+    if (0 && avs->codec->codec_id == AV_CODEC_ID_MPEG1VIDEO)
     {
 	m_pAvContext = avcodec_alloc_context3(NULL);
 	//AVCodec* codec = avcodec_find_encoder(avs->codec->codec_id);
@@ -60,7 +60,7 @@
 	    AVCodec* codec = avcodec_find_decoder(avs->codec->codec_id);
 	    if (codec && avcodec_open2(m_pAvContext, codec, NULL) == 0)
 	    {
-		m_pAvContext->flags |= CODEC_FLAG_TRUNCATED;
+		m_pAvContext->flags |= AV_CODEC_FLAG_TRUNCATED;
 		m_pAvContext->skip_idct = m_pAvContext->skip_frame = AVDISCARD_ALL;
 		//printf("Opened hurryup decoder %p  %p\n", codec, m_pAvContext->codec->decode);
 	    }
--- avifile-0.7-0.7.45/plugins/libffmpeg/FFAudioDecoder.cpp.orig	2020-08-29 21:50:27.323715047 +0200
+++ avifile-0.7-0.7.45/plugins/libffmpeg/FFAudioDecoder.cpp	2020-08-29 21:50:31.260360387 +0200
@@ -49,18 +49,23 @@
             return -1;
 	}
     }
-    int framesz = 0;
+    int got_frame = 0;
     AVPacket avpkt;
     av_init_packet(&avpkt);
     avpkt.data = (uint8_t*)in_data;
     avpkt.size = in_size;
-    int hr = avcodec_decode_audio3(m_pAvContext, (int16_t*)out_data, &framesz,
+    AVFrame *decoded_frame = av_frame_alloc();
+    int hr = avcodec_decode_audio4(m_pAvContext, decoded_frame, &got_frame,
 				  &avpkt);
-    //printf("CONVERT  i:%d  o:%d  f:%d   h:%d\n", in_size, out_size, framesz, hr);
+    int data_size = av_samples_get_buffer_size(NULL, m_pAvContext->channels, decoded_frame->nb_samples, m_pAvContext->sample_fmt, 1);
     if (size_read)
 	*size_read = (hr < 0) ? in_size : hr;
     if (size_written)
-	*size_written = framesz;
+	*size_written = data_size;
+
+    if (hr > 0)
+        memcpy(out_data, decoded_frame->data[0], data_size);
+    av_free(decoded_frame);
 
     if (hr < 0)
     {
--- avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoDecoder.cpp.orig	2020-08-29 20:47:30.190844199 +0200
+++ avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoDecoder.cpp	2020-08-30 17:57:09.138147425 +0200
@@ -17,6 +17,12 @@
 #endif
 
 #define Debug if (0)
+
+struct BufferData {
+    void *decoder;
+    AVFrame *pic;
+};
+
 AVM_BEGIN_NAMESPACE;
 
 FFVideoDecoder::FFVideoDecoder(AVCodec* av, const CodecInfo& info, const BITMAPINFOHEADER& bh, int flip)
@@ -31,7 +37,7 @@
     if (1 && m_pFormat->biCompression == fccHFYU)
     {
 	// for now disabled
-	m_pAvCodec->capabilities &= ~(CODEC_CAP_DRAW_HORIZ_BAND | CODEC_CAP_DR1);
+	m_pAvCodec->capabilities &= ~(AV_CODEC_CAP_DRAW_HORIZ_BAND | AV_CODEC_CAP_DR1);
 	AVM_WRITE(m_Info.GetPrivateName(), "if you have troubles - use Win32 codec instead\n");
 	m_Caps = (CAPS) (m_Caps | CAP_YUY2);
     }
@@ -75,31 +81,39 @@
     d->m_pImg->Slice(&ci);
 }
 
+static void free_buffer(void *opaque, uint8_t *data);
+
 // callback to supply rendering buffer to ffmpeg
-static int get_buffer(AVCodecContext* avctx, AVFrame* pic)
+static int get_buffer2(AVCodecContext* avctx, AVFrame* pic, int flags)
 {
+    BufferData* buf_dat;
     FFVideoDecoder* d = (FFVideoDecoder*) avctx->opaque;
     CImage* pImage = d->m_pImg;
     d->m_bUsed = true;
-    if (avctx->pix_fmt != PIX_FMT_YUV420P || !pImage || !d->m_bDirect)
+    if (avctx->pix_fmt != AV_PIX_FMT_YUV420P || !pImage || !d->m_bDirect)
     {
 	Debug printf("FF: Unsupported pixel format for Dr1 %d\n", avctx->pix_fmt); //abort();
-        return avcodec_default_get_buffer(avctx, pic);
+        return avcodec_default_get_buffer2(avctx, pic, flags);
     }
 
     Debug printf("FF: GetBuffer %p  %dx%d  %d  %p:%p:%p  %f\n", pImage, avctx->width, avctx->height, pic->pict_type,
 		 pImage->Data(0), pImage->Data(2), pImage->Data(1), pImage->m_lTimestamp / 1000000.0);
 
     pic->opaque = pImage;
-    pic->data[0] = pImage->Data(0);
-    pic->data[1] = pImage->Data(2);
-    pic->data[2] = pImage->Data(1);
+    buf_dat = (BufferData*)av_malloc(sizeof(*buf_dat));
+    buf_dat->decoder = d;
+    buf_dat->pic = pic;
+    pic->buf[0] = av_buffer_create (pImage->Data(0), 0, free_buffer, buf_dat, 0);
+    pic->buf[1] = av_buffer_create (pImage->Data(2), 0, free_buffer, NULL, 0);
+    pic->buf[2] = av_buffer_create (pImage->Data(1), 0, free_buffer, NULL, 0);
+    pic->data[0] = pic->buf[0]->data;
+    pic->data[1] = pic->buf[1]->data;
+    pic->data[2] = pic->buf[2]->data;
     pic->linesize[0] = pImage->Stride(0);
     // Note: most ffmpeg codecs linsize[1] == linesize[2] !
     pic->linesize[1] = pImage->Stride(2);
     pic->linesize[2] = pImage->Stride(1);
     pic->pts = pImage->m_lTimestamp;
-    pic->type = FF_BUFFER_TYPE_USER;
     pImage->m_iType = pic->pict_type;
     //pImage->m_iAge = (pic->pict_type == AV_PICTURE_TYPE_B) ?
     //pImage->m_iAge = (pic->reference) ?
@@ -129,21 +143,16 @@
     return 0;
 }
 
-static void release_buffer(struct AVCodecContext* avctx, AVFrame* pic)
+static void free_buffer(void *opaque, uint8_t *data)
 {
-    if (pic->type == FF_BUFFER_TYPE_USER)
-    {
-	FFVideoDecoder* d = (FFVideoDecoder*) avctx->opaque;
-	d->m_pReleased = (CImage*) pic->opaque;
-	Debug printf("FF: Released buffer %p  %p\n", pic->opaque, pic);
-	for (int i = 4; i >= 0; i--)
-	    pic->data[i]= NULL;
-	pic->opaque = NULL;
-    }
-    else
+    if (opaque)
     {
-	Debug printf("******************************\n");
-	avcodec_default_release_buffer(avctx, pic);
+	BufferData *buf_dat = (BufferData *) opaque;
+	FFVideoDecoder* d = (FFVideoDecoder*) buf_dat->decoder;
+	d->m_pReleased = (CImage*) buf_dat->pic->opaque;
+	Debug printf("FF: Released buffer %p  %p\n", buf_dat->pic->opaque, buf_dat->pic);
+	buf_dat->pic->opaque = NULL;
+	av_free(buf_dat);
     }
 }
 
@@ -171,8 +180,7 @@
 	m_pAvContext->bits_per_coded_sample = m_pFormat->biBitCount;
         m_pAvContext->width = m_Dest.biWidth;
 	m_pAvContext->height = (m_Dest.biHeight < 0) ? -m_Dest.biHeight : m_Dest.biHeight;
-	m_pAvContext->get_buffer = avcodec_default_get_buffer;
-	m_pAvContext->release_buffer = avcodec_default_release_buffer;
+	m_pAvContext->get_buffer2 = avcodec_default_get_buffer2;
 
 	if (m_pFormat->biSize > sizeof(BITMAPINFOHEADER)
 #if 0
@@ -200,7 +208,7 @@
 	const char* drtxt = "doesn't support DR1\n";
 
 	m_bDirect = false;
-	if (m_pAvCodec->capabilities & CODEC_CAP_DR1)
+	if (m_pAvCodec->capabilities & AV_CODEC_CAP_DR1)
 	{
 	    drtxt = "not using DR1\n";
 	    if (pImage)
@@ -220,12 +228,10 @@
 		{
 		    // for DR we needs some special width aligment
 		    // also there are some more limitation
-		    m_pAvContext->flags |= CODEC_FLAG_EMU_EDGE;
 		    drtxt = "using DR1\n";
                     m_bDirect = true;
 
-		    m_pAvContext->get_buffer = get_buffer;
-		    m_pAvContext->release_buffer = release_buffer;
+		    m_pAvContext->get_buffer2 = get_buffer2;
 		}
 	    }
 	}
@@ -234,8 +240,8 @@
 	m_bRestart = false;
 
 	if (m_Info.fourcc == RIFFINFO_MPG1
-	    && m_pAvCodec->capabilities & CODEC_CAP_TRUNCATED)
-	    m_pAvContext->flags |= CODEC_FLAG_TRUNCATED;
+	    && m_pAvCodec->capabilities & AV_CODEC_CAP_TRUNCATED)
+	    m_pAvContext->flags |= AV_CODEC_FLAG_TRUNCATED;
 
 	//m_pAvContext->error_resilience = 2;
         //m_pAvContext->error_concealment = 3;
@@ -299,7 +305,7 @@
     // try using draw_horiz_band if DR1 is unsupported
     m_pAvContext->draw_horiz_band =
 	(!m_bDirect && pImage && pImage->Format() == IMG_FMT_YV12
-	 && (m_pAvCodec->capabilities & CODEC_CAP_DRAW_HORIZ_BAND)
+	 && (m_pAvCodec->capabilities & AV_CODEC_CAP_DRAW_HORIZ_BAND)
 	 && !pImage->Direction() && render) ? draw_slice : 0;
     m_pAvContext->opaque = this;
 
@@ -324,7 +330,7 @@
 	AVM_WRITE(m_Info.GetPrivateName(), "WARNING: FFVideoDecoder::DecodeFrame() hr=%d\n", hr);
 	return hr;
     }
-    if (!(m_pAvContext->flags & CODEC_FLAG_TRUNCATED))
+    if (!(m_pAvContext->flags & AV_CODEC_FLAG_TRUNCATED))
     {
 	hr = size;
         //m_bUsed = true;
@@ -368,7 +374,6 @@
 	    return hr | NO_PICTURE;
         // let's fake got_picture;
 	if (!pic.opaque) {
-	    pic.type = FF_BUFFER_TYPE_USER;
 	    pic.opaque = m_pReleased;
 	}
         got_picture = true;
@@ -382,14 +387,14 @@
 	int imfmt = 0;
 	switch (m_pAvContext->pix_fmt)
 	{
-	case PIX_FMT_BGR24: imfmt = IMG_FMT_BGR24; break;
-	case PIX_FMT_RGB32: imfmt = IMG_FMT_BGR32; break;
-	case PIX_FMT_YUYV422: imfmt = IMG_FMT_YUY2; break;
-	case PIX_FMT_YUV410P: imfmt = IMG_FMT_I410; break;
-	case PIX_FMT_YUV411P: imfmt = IMG_FMT_I411; break;
-	case PIX_FMT_YUV420P: imfmt = IMG_FMT_I420; break;
-	case PIX_FMT_YUV422P: imfmt = IMG_FMT_I422; break;
-	case PIX_FMT_YUV444P: imfmt = IMG_FMT_I444; break;
+	case AV_PIX_FMT_BGR24: imfmt = IMG_FMT_BGR24; break;
+	case AV_PIX_FMT_RGB32: imfmt = IMG_FMT_BGR32; break;
+	case AV_PIX_FMT_YUYV422: imfmt = IMG_FMT_YUY2; break;
+	case AV_PIX_FMT_YUV410P: imfmt = IMG_FMT_I410; break;
+	case AV_PIX_FMT_YUV411P: imfmt = IMG_FMT_I411; break;
+	case AV_PIX_FMT_YUV420P: imfmt = IMG_FMT_I420; break;
+	case AV_PIX_FMT_YUV422P: imfmt = IMG_FMT_I422; break;
+	case AV_PIX_FMT_YUV444P: imfmt = IMG_FMT_I444; break;
 	default: break;
 	}
 	if (imfmt) {
@@ -415,11 +420,8 @@
     //printf("SWAP  %d  %d\n", m_Order.front().position, pImage->m_uiPosition);
     //printf("P   %d    %lld\n", p, m_Order[0].timestamp, m_Order.size());
 
-    //printf("PICTYPE %d  %p   %p  %d\n", pic.type, m_pReleased, pOut, FF_BUFFER_TYPE_USER);
 #if 1
-    if (pOut && pic.opaque &&
-	((pic.type == FF_BUFFER_TYPE_USER)
-	 || (pic.type == FF_BUFFER_TYPE_COPY)))
+    if (pOut && pic.opaque)
     {
 	*pOut = (CImage*) pic.opaque;
 	(*pOut)->m_lTimestamp = m_Order[0].timestamp;
--- avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoEncoder.cpp.orig	2020-08-29 20:47:30.190844199 +0200
+++ avifile-0.7-0.7.45/plugins/libffmpeg/FFVideoEncoder.cpp	2020-08-30 18:06:20.805158789 +0200
@@ -220,11 +220,15 @@
     //printf("ECDING FF  %p %p %p   sz:%d\n", f.data[0], f.data[1], f.data[2], GetOutputSize());
     //printf("ECDING FF  %d %d %d\n", f.linesize[0], f.linesize[1], f.linesize[2]);
 
-    int rsize = avcodec_encode_video(m_pAvContext, (unsigned char*) dest,
-				     GetOutputSize(), &f);
+    AVPacket pkt;
+    pkt.data = (uint8_t*)dest;
+    pkt.size = GetOutputSize();
+    int got_output;
+
+    int ret = avcodec_encode_video2(m_pAvContext, &pkt, &f, &got_output);
     //printf("ECDING FF  size %d\n", rsize);
     if (size)
-	*size = rsize;
+	*size = pkt.size;
     if (is_keyframe) {
 	*is_keyframe = m_pAvContext->coded_frame->key_frame ? 16 : 0;
 	//printf("KEYFRAME %d\n", *is_keyframe);
